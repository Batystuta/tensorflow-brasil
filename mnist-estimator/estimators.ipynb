{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador de Imagens usando TensorFlow Estimators\n",
    "\n",
    "Neste notebook iremos implementadar um modelo para classificação de imagens. Classificação é uma das \"tarefas\" em que podemos utilizar Machine Learning, nesta tarefa o ensino é **supervisionado**, em outras palavras nós vamos ensinar ao modelo através de exemplos com gabarito.\n",
    "\n",
    "Nosso modelo deverá receber imagens do [dataset MNIST](https://en.wikipedia.org/wiki/MNIST_database) e identificar a que **classe** (dígito de 0 a 9) estas imagens pertencem.\n",
    "\n",
    "## Dados\n",
    "\n",
    "Os dados foram retirados da base de dados [MNIST](https://en.wikipedia.org/wiki/MNIST_database). Este dataset já vem separado em treino e teste e contém 60.000 imagens de treino e 10.000 imagens de teste. Cada imagem tem dimensões 28x28, em preto e branco e representa um dígito desenhado a mão. Além disso cada imagem acompanha uma label que nos diz qual dígito essa imagem representa, de modo que este dataset é perfeito para classificação.\n",
    "\n",
    "## Modelo\n",
    "\n",
    "Iremos utilizar diferentes modelos com diferentes níveis de complexidade.\n",
    "\n",
    "## Créditos\n",
    "\n",
    "Essa atividade é baseada no notebook encontrado [aqui](https://github.com/mari-linhares/tensorflow-workshop/blob/master/workshops/cdnextcon_2017/Walk-Through.ipynb).\n",
    "\n",
    "Além disso para mais informações sobre Estimators [este](goo.gl/DBeUkN) é um ótimo material para mais detalhes!\n",
    "\n",
    "Obrigada a todos os envolvidos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sua versão do TensorFlow: 1.4.1\n",
      "Recomenda-se para esta atividade uma versão >= 1.4.0\n"
     ]
    }
   ],
   "source": [
    "# Compatibilidade entre Python 2 e Python 3\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "# MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)  # Permitindo visualização de logs\n",
    "\n",
    "# Bibliotecas auxiliares\n",
    "import numpy as np  # manipular vetores\n",
    "import matplotlib.pyplot as plt  # plotar imagens\n",
    "%matplotlib inline\n",
    "\n",
    "# IMPORTANTE: essa linha garante que os números gerados aleatoriamente são previsíveis\n",
    "np.random.seed(0)\n",
    "\n",
    "print ('Sua versão do TensorFlow:', tf.__version__)\n",
    "print ('Recomenda-se para esta atividade uma versão >= 1.4.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/MNIST/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Buscando dados de treino e teste\n",
    "mnist = input_data.read_data_sets('/tmp/MNIST/', one_hot=True)\n",
    "\n",
    "# x_treino: imagens, y_treino: labels\n",
    "x_treino = mnist.train.images\n",
    "y_treino = mnist.train.labels\n",
    "x_teste = mnist.test.images\n",
    "y_teste = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando os dados\n",
    "\n",
    "Após manipular ou modificar os dados é sempre importante garantir que os dados estão no formato esperado e não foram corrompidos ou alterados indevidamente. Para isto vamos escolher algumas imagens do conjunto de treino aleatoriamente e verificá-las.\n",
    "\n",
    "> IMPORTANTE: para modelos reais é importante garantir a qualidade e integridade dos dados com maior rigor já que é fundamental a \"saúde\" dos dados para se obter um bom modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato das imagens de treino: (55000, 784)\n",
      "Número de labels de treino: 55000\n",
      "--------------------------------------------------\n",
      "Formato das imagens de teste: (10000, 784)\n",
      "Número de labels de teste: 10000\n"
     ]
    }
   ],
   "source": [
    "print ('Formato das imagens de treino:', x_treino.shape)\n",
    "print ('Número de labels de treino:', y_treino.shape[0])\n",
    "print ('-' * 50)\n",
    "print ('Formato das imagens de teste:', x_teste.shape)\n",
    "print ('Número de labels de teste:', y_teste.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos apenas 550000 dados de treino, porque nesta versão do MNIST 5000 exemplos foram separados para serem usados como avaliação. Além disso vemos o valor 784, pois as imagens são 28x28 píxels, ou de outra forma 784 píxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplos de 5 imagens da base de treino\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABpCAYAAAAqXNiiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff153dbe950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualizar_dados_treino(num_dados):\n",
    "    '''Essa função apresenta alguns dados de treino (imagens, labels) escolhidos aleatoriamente.\n",
    "       Parâmetros:\n",
    "           num_dados (int): número de dados que serão apresentados \n",
    "    '''\n",
    "\n",
    "    print('Exemplos de %d imagens da base de treino' % num_dados)\n",
    "    \n",
    "    # Escolhemos índices aleatórios\n",
    "    random_indices = np.random.randint(0, x_treino.shape[0], num_dados)\n",
    "    \n",
    "    # Buscando imagens e labels\n",
    "    imagens = x_treino[random_indices]\n",
    "    labels = y_treino[random_indices]\n",
    "    \n",
    "    # Plottando imagens\n",
    "    for index, (img, label) in enumerate(zip(imagens, labels)):\n",
    "        plt.subplot(2, num_dados, index + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.reshape(img, (28, 28)), cmap='gray', interpolation='nearest')\n",
    "        plt.title('%i' % np.argmax(label))\n",
    "    plt.show()\n",
    "\n",
    "visualizar_dados_treino(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input function de treino\n",
    "mnist_treino_input = tf.estimator.inputs.numpy_input_fn(\n",
    "  # os dados devem ser passados como um dicionário, contendo cada feature\n",
    "  # como nossa entrada é uma imagem, ou seja, apenas uma feature\n",
    "  # temos apenas uma chave no dicionário 'x' cujo valor são as imagens  \n",
    "  {'x': np.array(x_treino, dtype=np.float32) },\n",
    "  # os labels esperados para numpy_input_fn é um vetor numpy\n",
    "  np.array(y_treino, dtype=np.int32),\n",
    "  # sempre importanto \"misturar\" os dados de treino\n",
    "  shuffle=True,\n",
    "  # este parâmetro = None, implica em repetir os dados de forma \"circular\"\n",
    "  # iremos controlar o número de interações durante o treino do modelo.\n",
    "  num_epochs=None)\n",
    "\n",
    "# Input function de teste\n",
    "mnist_teste_input = tf.estimator.inputs.numpy_input_fn(\n",
    "  # da mesma forma os dados devem ser passados como um dicionário\n",
    "  {'x':np.array(x_teste, dtype=np.float32)},\n",
    "  # labels\n",
    "  np.array(y_teste, dtype=np.int32),\n",
    "  # misturando os dados\n",
    "  shuffle=True,\n",
    "  # sem repetir os dados\n",
    "  num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_layer, mode):\n",
    "    with tf.name_scope(\"conv1\"):  \n",
    "      conv1 = tf.layers.conv2d(inputs=input_layer,filters=32, kernel_size=[5, 5],\n",
    "                               padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    with tf.name_scope(\"pool1\"):  \n",
    "      pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    with tf.name_scope(\"conv2\"):  \n",
    "      conv2 = tf.layers.conv2d(inputs=pool1,filters=64, kernel_size=[5, 5],\n",
    "                               padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    with tf.name_scope(\"pool2\"):  \n",
    "      pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    with tf.name_scope(\"dense\"):  \n",
    "      pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "      dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    with tf.name_scope(\"dropout\"): \n",
    "      # dropout apenas se estivermos treinando\n",
    "      # você pode aprender mais sobre dropout e CNNs aqui:\n",
    "      # https://en.wikipedia.org/wiki/Convolutional_neural_network#Dropout \n",
    "      is_training_mode = mode == tf.estimator.ModeKeys.TRAIN\n",
    "      dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=is_training_mode)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    return logits\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "  # Deve conter os seguintes passos:\n",
    "  \n",
    "  # 1. Definir o modelo via TF\n",
    "  if params['model'] == 'simples':\n",
    "    output = tf.layers.dense(inputs=features['x'], units=10)\n",
    "  elif params['model'] == 'CNN':\n",
    "    # mudando a shape da entrada para a esperada pela CNN\n",
    "    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "    output = build_cnn(input_layer, mode)\n",
    "  \n",
    "  \n",
    "  # 2. Definir como gerar predições\n",
    "  predicoes = {\n",
    "      'classes': tf.argmax(input=output, axis=1),\n",
    "      'probabilidades': tf.nn.softmax(output, name='softmax_tensor')\n",
    "  }\n",
    "  \n",
    "  # Se estamos realizando predição precisamos apenas especificar estas operações ;)\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    # Return an EstimatorSpec object\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predicoes)\n",
    "  \n",
    "  \n",
    "  # 3. Definir a loss function para treino e avaliação\n",
    "  # loss => erro, como calcular nosso erro?\n",
    "  loss =  tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=output)\n",
    "\n",
    "\n",
    "  # Se estamos treinando precisamos definir como otimizar nosso modelo\n",
    "  # Para o Estimator esta definição é chamada train_op\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    \n",
    "    # 4. Definir como otimizar o modelo (optimizer)\n",
    "    # como otimizar nosso modelo utilizando o erro que calculamos?\n",
    "    # Neste exemplo estamos usando um algoritmo de otimizacao chamado Adam\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.train.get_global_step(),\n",
    "      learning_rate=params['learning_rate'],\n",
    "      optimizer=params['optimizer'])\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predicoes,\n",
    "                                      loss=loss, train_op=train_op)\n",
    "  \n",
    "  \n",
    "  # 5. Definir métricas para avaliação\n",
    "  eval_metric_ops = {\n",
    "      'acuracia': tf.metrics.accuracy(\n",
    "          tf.argmax(input=output, axis=1),\n",
    "          tf.argmax(input=labels, axis=1))\n",
    "  }\n",
    "  \n",
    "  # 6. Retornar um EstimatorSpec definindo os passos acima\n",
    "  return tf.estimator.EstimatorSpec(mode=mode, predictions=predicoes,\n",
    "                                      loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando o Modelo Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff14ab0af50>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'output/simples/', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into output/simples/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.47138, step = 1\n",
      "INFO:tensorflow:global_step/sec: 385.941\n",
      "INFO:tensorflow:loss = 2.06453, step = 101 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.805\n",
      "INFO:tensorflow:loss = 1.77982, step = 201 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.71\n",
      "INFO:tensorflow:loss = 1.40163, step = 301 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.552\n",
      "INFO:tensorflow:loss = 1.38768, step = 401 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.486\n",
      "INFO:tensorflow:loss = 1.26239, step = 501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.749\n",
      "INFO:tensorflow:loss = 1.10428, step = 601 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.838\n",
      "INFO:tensorflow:loss = 1.04108, step = 701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.318\n",
      "INFO:tensorflow:loss = 0.919226, step = 801 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.094\n",
      "INFO:tensorflow:loss = 0.86501, step = 901 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.3\n",
      "INFO:tensorflow:loss = 0.832688, step = 1001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.95\n",
      "INFO:tensorflow:loss = 0.705194, step = 1101 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.938\n",
      "INFO:tensorflow:loss = 0.621611, step = 1201 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.115\n",
      "INFO:tensorflow:loss = 0.727658, step = 1301 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.064\n",
      "INFO:tensorflow:loss = 0.655461, step = 1401 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.73\n",
      "INFO:tensorflow:loss = 0.617763, step = 1501 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.433\n",
      "INFO:tensorflow:loss = 0.729259, step = 1601 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.833\n",
      "INFO:tensorflow:loss = 0.58838, step = 1701 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.689\n",
      "INFO:tensorflow:loss = 0.662318, step = 1801 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.19\n",
      "INFO:tensorflow:loss = 0.598353, step = 1901 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.871\n",
      "INFO:tensorflow:loss = 0.437817, step = 2001 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.445\n",
      "INFO:tensorflow:loss = 0.677874, step = 2101 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.848\n",
      "INFO:tensorflow:loss = 0.499655, step = 2201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.135\n",
      "INFO:tensorflow:loss = 0.615545, step = 2301 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.044\n",
      "INFO:tensorflow:loss = 0.52517, step = 2401 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.251\n",
      "INFO:tensorflow:loss = 0.463425, step = 2501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.12\n",
      "INFO:tensorflow:loss = 0.522043, step = 2601 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.096\n",
      "INFO:tensorflow:loss = 0.497042, step = 2701 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.296\n",
      "INFO:tensorflow:loss = 0.467672, step = 2801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.604\n",
      "INFO:tensorflow:loss = 0.507501, step = 2901 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.783\n",
      "INFO:tensorflow:loss = 0.441476, step = 3001 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.463\n",
      "INFO:tensorflow:loss = 0.405004, step = 3101 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.107\n",
      "INFO:tensorflow:loss = 0.443597, step = 3201 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.438\n",
      "INFO:tensorflow:loss = 0.250471, step = 3301 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.582\n",
      "INFO:tensorflow:loss = 0.352324, step = 3401 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.805\n",
      "INFO:tensorflow:loss = 0.59335, step = 3501 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.346\n",
      "INFO:tensorflow:loss = 0.418243, step = 3601 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.008\n",
      "INFO:tensorflow:loss = 0.269921, step = 3701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.654\n",
      "INFO:tensorflow:loss = 0.326897, step = 3801 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.371\n",
      "INFO:tensorflow:loss = 0.267581, step = 3901 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.764\n",
      "INFO:tensorflow:loss = 0.392839, step = 4001 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.025\n",
      "INFO:tensorflow:loss = 0.281819, step = 4101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.551\n",
      "INFO:tensorflow:loss = 0.410737, step = 4201 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.987\n",
      "INFO:tensorflow:loss = 0.436809, step = 4301 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.667\n",
      "INFO:tensorflow:loss = 0.308636, step = 4401 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.423\n",
      "INFO:tensorflow:loss = 0.336353, step = 4501 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.022\n",
      "INFO:tensorflow:loss = 0.299826, step = 4601 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.328\n",
      "INFO:tensorflow:loss = 0.352277, step = 4701 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.613\n",
      "INFO:tensorflow:loss = 0.495082, step = 4801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.891\n",
      "INFO:tensorflow:loss = 0.388826, step = 4901 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.675\n",
      "INFO:tensorflow:loss = 0.422071, step = 5001 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.075\n",
      "INFO:tensorflow:loss = 0.439963, step = 5101 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.968\n",
      "INFO:tensorflow:loss = 0.473246, step = 5201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.597\n",
      "INFO:tensorflow:loss = 0.373467, step = 5301 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.94\n",
      "INFO:tensorflow:loss = 0.554934, step = 5401 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.351\n",
      "INFO:tensorflow:loss = 0.303329, step = 5501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.221\n",
      "INFO:tensorflow:loss = 0.24773, step = 5601 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.917\n",
      "INFO:tensorflow:loss = 0.271291, step = 5701 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.648\n",
      "INFO:tensorflow:loss = 0.29956, step = 5801 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.954\n",
      "INFO:tensorflow:loss = 0.279478, step = 5901 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.191\n",
      "INFO:tensorflow:loss = 0.284832, step = 6001 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.213\n",
      "INFO:tensorflow:loss = 0.476444, step = 6101 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.715\n",
      "INFO:tensorflow:loss = 0.248631, step = 6201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.185\n",
      "INFO:tensorflow:loss = 0.235839, step = 6301 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.854\n",
      "INFO:tensorflow:loss = 0.332925, step = 6401 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.602\n",
      "INFO:tensorflow:loss = 0.203712, step = 6501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.262\n",
      "INFO:tensorflow:loss = 0.33604, step = 6601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.24\n",
      "INFO:tensorflow:loss = 0.329944, step = 6701 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.396\n",
      "INFO:tensorflow:loss = 0.327867, step = 6801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.623\n",
      "INFO:tensorflow:loss = 0.259998, step = 6901 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.849\n",
      "INFO:tensorflow:loss = 0.411288, step = 7001 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.042\n",
      "INFO:tensorflow:loss = 0.342681, step = 7101 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.267\n",
      "INFO:tensorflow:loss = 0.448845, step = 7201 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.541\n",
      "INFO:tensorflow:loss = 0.216944, step = 7301 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.598\n",
      "INFO:tensorflow:loss = 0.287748, step = 7401 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.783\n",
      "INFO:tensorflow:loss = 0.266023, step = 7501 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.125\n",
      "INFO:tensorflow:loss = 0.228811, step = 7601 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.273625, step = 7701 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.902\n",
      "INFO:tensorflow:loss = 0.288287, step = 7801 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.964\n",
      "INFO:tensorflow:loss = 0.442449, step = 7901 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.635\n",
      "INFO:tensorflow:loss = 0.287631, step = 8001 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.564\n",
      "INFO:tensorflow:loss = 0.278402, step = 8101 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.397\n",
      "INFO:tensorflow:loss = 0.393412, step = 8201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.034\n",
      "INFO:tensorflow:loss = 0.296046, step = 8301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.286\n",
      "INFO:tensorflow:loss = 0.4378, step = 8401 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.579\n",
      "INFO:tensorflow:loss = 0.412753, step = 8501 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.31\n",
      "INFO:tensorflow:loss = 0.316778, step = 8601 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.344\n",
      "INFO:tensorflow:loss = 0.381396, step = 8701 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.299\n",
      "INFO:tensorflow:loss = 0.408094, step = 8801 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.55\n",
      "INFO:tensorflow:loss = 0.296782, step = 8901 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:loss = 0.229216, step = 9001 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.002\n",
      "INFO:tensorflow:loss = 0.30107, step = 9101 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.019\n",
      "INFO:tensorflow:loss = 0.279641, step = 9201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.457\n",
      "INFO:tensorflow:loss = 0.367887, step = 9301 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.47\n",
      "INFO:tensorflow:loss = 0.446262, step = 9401 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.085\n",
      "INFO:tensorflow:loss = 0.314523, step = 9501 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.4\n",
      "INFO:tensorflow:loss = 0.342775, step = 9601 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.686\n",
      "INFO:tensorflow:loss = 0.329514, step = 9701 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.996\n",
      "INFO:tensorflow:loss = 0.31502, step = 9801 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.172\n",
      "INFO:tensorflow:loss = 0.406131, step = 9901 (0.232 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into output/simples/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.295722.\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-28-23:56:10\n",
      "INFO:tensorflow:Restoring parameters from output/simples/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-28-23:56:11\n",
      "INFO:tensorflow:Saving dict for global step 10000: acuracia = 0.9161, global_step = 10000, loss = 0.300726\n",
      "{'loss': 0.30072638, 'global_step': 10000, 'acuracia': 0.91610003}\n"
     ]
    }
   ],
   "source": [
    "# Criando nosso modelo simples\n",
    "model_params = {\n",
    "  'optimizer': 'Adam',\n",
    "  'learning_rate': 1e-4,\n",
    "  'model': 'simples'\n",
    "}\n",
    "\n",
    "# model_dir indica onde salvar os dados do modelo (pesos, logs, arquivos tensorboard)\n",
    "modelo_simples = tf.estimator.Estimator(model_fn=model_fn, params=model_params, model_dir='output/simples/')\n",
    "\n",
    "# Treino por 10000 passos\n",
    "modelo_simples.train(input_fn=mnist_treino_input, steps=10000)\n",
    "\n",
    "# Avaliando modelo\n",
    "print (modelo_simples.evaluate(input_fn=mnist_teste_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff14ae5ccd0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'output/cnn/', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from output/cnn/model.ckpt-1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.29218, step = 2\n",
      "INFO:tensorflow:global_step/sec: 1.87363\n",
      "INFO:tensorflow:loss = 0.537803, step = 102 (53.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.01702\n",
      "INFO:tensorflow:loss = 0.258778, step = 202 (49.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.9337\n",
      "INFO:tensorflow:loss = 0.356951, step = 302 (51.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.14129\n",
      "INFO:tensorflow:loss = 0.23724, step = 402 (46.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.14057\n",
      "INFO:tensorflow:loss = 0.241406, step = 502 (46.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00757\n",
      "INFO:tensorflow:loss = 0.125222, step = 602 (49.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.98569\n",
      "INFO:tensorflow:loss = 0.197435, step = 702 (50.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00374\n",
      "INFO:tensorflow:loss = 0.0323514, step = 802 (49.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00168\n",
      "INFO:tensorflow:loss = 0.0729957, step = 902 (49.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.97515\n",
      "INFO:tensorflow:loss = 0.0558156, step = 1002 (50.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00581\n",
      "INFO:tensorflow:loss = 0.111039, step = 1102 (49.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99785\n",
      "INFO:tensorflow:loss = 0.0641901, step = 1202 (50.054 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1205 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.97192\n",
      "INFO:tensorflow:loss = 0.0628514, step = 1302 (50.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.97581\n",
      "INFO:tensorflow:loss = 0.118338, step = 1402 (50.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.01702\n",
      "INFO:tensorflow:loss = 0.0759767, step = 1502 (49.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99847\n",
      "INFO:tensorflow:loss = 0.0879318, step = 1602 (50.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.94755\n",
      "INFO:tensorflow:loss = 0.0324749, step = 1702 (51.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.22893\n",
      "INFO:tensorflow:loss = 0.05801, step = 1802 (81.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0453\n",
      "INFO:tensorflow:loss = 0.0788965, step = 1902 (95.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03561\n",
      "INFO:tensorflow:loss = 0.0440335, step = 2002 (96.562 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2085 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.09428\n",
      "INFO:tensorflow:loss = 0.0588678, step = 2102 (91.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00888\n",
      "INFO:tensorflow:loss = 0.0156549, step = 2202 (99.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.981989\n",
      "INFO:tensorflow:loss = 0.033121, step = 2302 (101.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.05911\n",
      "INFO:tensorflow:loss = 0.0831359, step = 2402 (94.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46149\n",
      "INFO:tensorflow:loss = 0.050587, step = 2502 (68.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.01706\n",
      "INFO:tensorflow:loss = 0.0569051, step = 2602 (49.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.74051\n",
      "INFO:tensorflow:loss = 0.022221, step = 2702 (57.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.97863\n",
      "INFO:tensorflow:loss = 0.0304535, step = 2802 (50.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.005\n",
      "INFO:tensorflow:loss = 0.0411597, step = 2902 (49.875 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2930 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.9856\n",
      "INFO:tensorflow:loss = 0.0616095, step = 3002 (50.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.06386\n",
      "INFO:tensorflow:loss = 0.0424428, step = 3102 (48.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.0631\n",
      "INFO:tensorflow:loss = 0.0430055, step = 3202 (48.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.05209\n",
      "INFO:tensorflow:loss = 0.0712266, step = 3302 (48.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.02756\n",
      "INFO:tensorflow:loss = 0.0276174, step = 3402 (49.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.06829\n",
      "INFO:tensorflow:loss = 0.00901431, step = 3502 (48.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71071\n",
      "INFO:tensorflow:loss = 0.053225, step = 3602 (58.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7884\n",
      "INFO:tensorflow:loss = 0.0195332, step = 3702 (55.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.73026\n",
      "INFO:tensorflow:loss = 0.0160023, step = 3802 (57.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88019\n",
      "INFO:tensorflow:loss = 0.00622014, step = 3902 (53.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.09767\n",
      "INFO:tensorflow:loss = 0.0309616, step = 4002 (47.672 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4101 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.07309\n",
      "INFO:tensorflow:loss = 0.0290229, step = 4102 (48.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.01696\n",
      "INFO:tensorflow:loss = 0.0422397, step = 4202 (49.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.9552\n",
      "INFO:tensorflow:loss = 0.032301, step = 4302 (51.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.95178\n",
      "INFO:tensorflow:loss = 0.00462513, step = 4402 (51.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.08249\n",
      "INFO:tensorflow:loss = 0.0167828, step = 4502 (48.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.08689\n",
      "INFO:tensorflow:loss = 0.0507592, step = 4602 (47.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.97396\n",
      "INFO:tensorflow:loss = 0.014692, step = 4702 (50.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.03777\n",
      "INFO:tensorflow:loss = 0.0049959, step = 4802 (49.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.03984\n",
      "INFO:tensorflow:loss = 0.0154621, step = 4902 (49.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.01997\n",
      "INFO:tensorflow:loss = 0.0360113, step = 5002 (49.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.06792\n",
      "INFO:tensorflow:loss = 0.153277, step = 5102 (48.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.0821\n",
      "INFO:tensorflow:loss = 0.0389864, step = 5202 (48.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.06779\n",
      "INFO:tensorflow:loss = 0.00998848, step = 5302 (48.362 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5320 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.07563\n",
      "INFO:tensorflow:loss = 0.0153415, step = 5402 (48.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.09665\n",
      "INFO:tensorflow:loss = 0.0586442, step = 5502 (47.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99995\n",
      "INFO:tensorflow:loss = 0.0210554, step = 5602 (50.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.05362\n",
      "INFO:tensorflow:loss = 0.0110301, step = 5702 (48.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.91436\n",
      "INFO:tensorflow:loss = 0.0773669, step = 5802 (52.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.97936\n",
      "INFO:tensorflow:loss = 0.0226212, step = 5902 (50.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.06728\n",
      "INFO:tensorflow:loss = 0.0115418, step = 6002 (48.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.04131\n",
      "INFO:tensorflow:loss = 0.00189075, step = 6102 (48.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.98579\n",
      "INFO:tensorflow:loss = 0.00707408, step = 6202 (50.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.97763\n",
      "INFO:tensorflow:loss = 0.0104474, step = 6302 (50.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.9944\n",
      "INFO:tensorflow:loss = 0.00417508, step = 6402 (50.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.05731\n",
      "INFO:tensorflow:loss = 0.00543906, step = 6502 (48.606 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6531 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.99018\n",
      "INFO:tensorflow:loss = 0.00923378, step = 6602 (50.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84948\n",
      "INFO:tensorflow:loss = 0.00274027, step = 6702 (54.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.85539\n",
      "INFO:tensorflow:loss = 0.0139777, step = 6802 (53.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.04665\n",
      "INFO:tensorflow:loss = 0.00928866, step = 6902 (48.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.62064\n",
      "INFO:tensorflow:loss = 0.00764831, step = 7002 (61.704 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.00402\n",
      "INFO:tensorflow:loss = 0.0151187, step = 7102 (49.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.02863\n",
      "INFO:tensorflow:loss = 0.00841472, step = 7202 (49.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.08032\n",
      "INFO:tensorflow:loss = 0.0186681, step = 7302 (48.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.07903\n",
      "INFO:tensorflow:loss = 0.00432059, step = 7402 (48.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.07924\n",
      "INFO:tensorflow:loss = 0.0381186, step = 7502 (48.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.12956\n",
      "INFO:tensorflow:loss = 0.017439, step = 7602 (46.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.12898\n",
      "INFO:tensorflow:loss = 0.0237805, step = 7702 (46.971 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7720 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.11463\n",
      "INFO:tensorflow:loss = 0.0539274, step = 7802 (47.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.92965\n",
      "INFO:tensorflow:loss = 0.00837943, step = 7902 (51.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.10667\n",
      "INFO:tensorflow:loss = 0.0113697, step = 8002 (47.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.11261\n",
      "INFO:tensorflow:loss = 0.00110762, step = 8102 (47.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.13956\n",
      "INFO:tensorflow:loss = 0.00294349, step = 8202 (46.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.14353\n",
      "INFO:tensorflow:loss = 0.0038587, step = 8302 (46.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.11208\n",
      "INFO:tensorflow:loss = 0.0021006, step = 8402 (47.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.13979\n",
      "INFO:tensorflow:loss = 0.0147865, step = 8502 (46.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.13824\n",
      "INFO:tensorflow:loss = 0.00288898, step = 8602 (46.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.13895\n",
      "INFO:tensorflow:loss = 0.0282822, step = 8702 (46.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.96278\n",
      "INFO:tensorflow:loss = 0.00343645, step = 8802 (50.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.85383\n",
      "INFO:tensorflow:loss = 0.00511474, step = 8902 (53.944 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8957 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.78308\n",
      "INFO:tensorflow:loss = 0.00247241, step = 9002 (56.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.69965\n",
      "INFO:tensorflow:loss = 0.0152453, step = 9102 (58.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88762\n",
      "INFO:tensorflow:loss = 0.00954088, step = 9202 (52.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82562\n",
      "INFO:tensorflow:loss = 0.00105084, step = 9302 (54.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.89726\n",
      "INFO:tensorflow:loss = 0.000645305, step = 9402 (52.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7675\n",
      "INFO:tensorflow:loss = 0.00595542, step = 9502 (56.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70179\n",
      "INFO:tensorflow:loss = 0.00272423, step = 9602 (58.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78949\n",
      "INFO:tensorflow:loss = 0.0422321, step = 9702 (55.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.60394\n",
      "INFO:tensorflow:loss = 0.0251728, step = 9802 (62.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.67289\n",
      "INFO:tensorflow:loss = 0.00216915, step = 9902 (59.777 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into output/cnn/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.011099.\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-29-01:27:51\n",
      "INFO:tensorflow:Restoring parameters from output/cnn/model.ckpt-10001\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-29-01:28:04\n",
      "INFO:tensorflow:Saving dict for global step 10001: acuracia = 0.9923, global_step = 10001, loss = 0.0246681\n",
      "{'loss': 0.024668077, 'global_step': 10001, 'acuracia': 0.99229997}\n"
     ]
    }
   ],
   "source": [
    "model_params['model'] = 'CNN'\n",
    "modelo_cnn = tf.estimator.Estimator(model_fn=model_fn, params=model_params, model_dir='output/cnn/')\n",
    "\n",
    "# Treino por 10000 passos\n",
    "modelo_cnn.train(input_fn=mnist_treino_input, steps=10000)\n",
    "\n",
    "# Avaliando modelo\n",
    "print (modelo_cnn.evaluate(input_fn=mnist_teste_input))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "\n",
    "Implementar a input function para predição de uma imagem e realizar tal predição, um exemplo de como fazer isso para outra base de dados pode ser visto [aqui](https://github.com/mari-linhares/tensorflow-brasil/blob/master/classificador-cachorros-gatos-estimator/classificador-de-imagens-estimators.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
